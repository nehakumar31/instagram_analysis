{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoaiQwqUuERq",
    "outputId": "a04280a5-6c2b-420d-9b6c-11b0c4aff6eb"
   },
   "source": [
    "**Approach - <br>- Data Reading and Understanding<br>- Preprocessing => removal of punctuations, numbers, lemmatization, fixing contractions, spelling correction<br> - Pretrained embeddings => glove embeddings https://nlp.stanford.edu/data/glove.twitter.27B.zip and emoji embeddings https://github.com/MirunaPislar/emoji2vec/tree/master/models <br>- Tokenizer to convert comments to sequences<br>- Model => Bidirectional LSTM with dropout<br>- Pipeline to execute tokenization and model in sequence<br>- Pipeline elements will be serialized to a pickle file to be used for predictions when invoked from StreamLit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zp7Cd1pAZEH"
   },
   "outputs": [],
   "source": [
    "#download glove embeddings\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "urllib.request.urlretrieve(\"https://nlp.stanford.edu/data/glove.twitter.27B.zip\", \"glove.27B.zip\")\n",
    "\n",
    "with zipfile.ZipFile(\"glove.27B.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_e3jHZZ5wtG",
    "outputId": "bbab7173-952a-4744-e5a1-06303795438e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nehkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nehkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nehkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nehkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#All imports\n",
    "from helpers import preprocessing\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.framework.ops import eager_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYcOTtu67VfC",
    "outputId": "92b922b0-ee73-4d40-8b92-592efdbfaca8"
   },
   "outputs": [],
   "source": [
    "#reload\n",
    "import importlib\n",
    "importlib.reload(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bX7zVYQr_O2B"
   },
   "outputs": [],
   "source": [
    "#constants\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SZ = 32\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88n3LmsF78EX"
   },
   "source": [
    "### Step 1 - Data Reading and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EoKRYzNm72r3",
    "outputId": "79eecddf-be04-43ac-c57d-dadb8b6e88bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hashtag hashtag hashtag hashtag hashtag hashta...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>send it pic _x000D_\\nüëÅ_x000D_\\nüëâ user</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if i get it on time maybe üò¢</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gorgeous ‚ù§</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòçüòçüòçüòç</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment Sentiment\n",
       "0  hashtag hashtag hashtag hashtag hashtag hashta...   Neutral\n",
       "1              send it pic _x000D_\\nüëÅ_x000D_\\nüëâ user   Neutral\n",
       "2                        if i get it on time maybe üò¢     Mixed\n",
       "3                                         gorgeous ‚ù§  Positive\n",
       "4                                               üòçüòçüòçüòç  Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load training data\n",
    "comments_df = pd.read_excel('./data/comments.xlsx', usecols=['comment','Sentiment' ])\n",
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StdYXT007__S",
    "outputId": "836b21b5-9f8e-4647-fe18-1efa435fcf5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11856 entries, 0 to 11855\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   comment    11856 non-null  object\n",
      " 1   Sentiment  11856 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 185.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#brief description of datatypes \n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kkttcmdo8DIM",
    "outputId": "5acc2254-b362-41c6-8cf1-c6917acc7660"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    0.813850\n",
       "Neutral     0.127783\n",
       "Negative    0.052800\n",
       "Mixed       0.005567\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['Sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20gKaiuW8KCG"
   },
   "source": [
    "### Step 2 - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Uye-6MQJ8GGi"
   },
   "outputs": [],
   "source": [
    "#data cleanup and preparation using helper module - \"preprocesing\"\n",
    "def prepare_data(df):\n",
    "  processed_df = preprocessing.preprocess_data(df, 'comment')  \n",
    "  processed_df = preprocessing.convert_emoticon(processed_df, 'spelling_corrected', False)\n",
    "  processed_df['cleaned_comment'] = processed_df['emoticon_converted']\n",
    "  return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YZr9K1SN8zwi"
   },
   "outputs": [],
   "source": [
    "cleaned_df = prepare_data(comments_df)\n",
    "\n",
    "X = cleaned_df['cleaned_comment']\n",
    "y = cleaned_df['Sentiment'].map({\"Neutral\":0, \"Positive\":1, \"Negative\":2, \"Mixed\":3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DTn6UPr9MXm"
   },
   "source": [
    "**Word Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jzlTkfhN9G88"
   },
   "outputs": [],
   "source": [
    "#load pre-trained glove embeddings\n",
    "pretrained_embeddings = dict()\n",
    "with open('./embeddings/glove.twitter.27B.100d.txt','r',encoding='utf-8') as file_handle:\n",
    "  for line in file_handle:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    pretrained_embeddings[word]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g9R6Pd7zKF__"
   },
   "outputs": [],
   "source": [
    "#load pre-trained emoji embeddings\n",
    "emoji_embeddings = dict()\n",
    "with open('./embeddings/emoji_embeddings_100d.txt','r',encoding='utf-8') as file_handle:\n",
    "  for line in file_handle:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    emoji_embeddings[word]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UuRdDt-h-MTn"
   },
   "outputs": [],
   "source": [
    "#helper function to convert input comments to embedding vector representation\n",
    "def vocab_embeddings(word_vocab):\n",
    "  num_words = len(word_vocab) + 1\n",
    "  word_embeddings = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "  for word, i in word_vocab.items():\n",
    "    if word in pretrained_embeddings:\n",
    "      word_embeddings[i] = pretrained_embeddings[word]\n",
    "    elif word in emoji_embeddings:\n",
    "      word_embeddings[i] = emoji_embeddings[word]\n",
    "\n",
    "  return word_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "491CK0t8BUgZ"
   },
   "source": [
    "**CustomTokenizer to convert comments to sequences meant to be used as a pipeline element**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tTqHnJmo6GwR"
   },
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "  def __init__(self):\n",
    "    #initialize tf tokenizer\n",
    "    self.tokenizer = Tokenizer()\n",
    "  \n",
    "  def _vectorize_input(self, comments):   \n",
    "    comments_seq = self.tokenizer.texts_to_sequences(comments)\n",
    "    comments_seq = sequence.pad_sequences(comments_seq, maxlen=self.max_length, padding='post', truncating='post')\n",
    "    return comments_seq\n",
    "\n",
    "  def fit_transform(self, comments, y=None):\n",
    "    \"\"\"invoked on training data to fit tokenizer and convert comments to sequences\"\"\"        \n",
    "    max_length = max(comments.map(len))\n",
    "    self.max_length = min(max_length, 30)\n",
    "    self.tokenizer.fit_on_texts(comments)\n",
    "    return self._vectorize_input(comments)    \n",
    "\n",
    "  def transform(self, comments):\n",
    "    \"\"\"invoked on testing/validation data to convert comments to sequences\"\"\"\n",
    "    return self._vectorize_input(comments)\n",
    "\n",
    "  def get_embeddings(self):\n",
    "    \"\"\"get vocab embeddings to be fed to embedding layer\"\"\"\n",
    "    word_embeddings = vocab_embeddings(self.tokenizer.word_index)\n",
    "    return word_embeddings\n",
    "\n",
    "  def get_input_dim(self):\n",
    "    \"\"\"input sequence dimension to be fed to embedding layer\"\"\"\n",
    "    return self.max_length  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "loxpVkyCsYhz"
   },
   "outputs": [],
   "source": [
    "#initialize tokenizer to be used in pipeline\n",
    "cust_tokenizer = CustomTokenizer()\n",
    "\n",
    "#transform target labels to one hot encoding\n",
    "y_transformed = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4EULTrxBPky"
   },
   "source": [
    "### Step 3 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RJtTKjKIO81t"
   },
   "outputs": [],
   "source": [
    "#evaluate model with f1 score to get a balance of precision and recall\n",
    "def f1_score(true, pred):\n",
    "  metric = tfa.metrics.F1Score(num_classes=4, average='weighted', threshold=0.5)\n",
    "  metric.update_state(true, pred)\n",
    "  result = metric.result()\n",
    "  return result.numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xK6wCY1Pit2p"
   },
   "outputs": [],
   "source": [
    "#helper function to plot metrics - accuracy, f1-score for training and val data\n",
    "def plot_results(x, metric, history):  \n",
    "  val_metric = 'val_' + metric\n",
    "  plt.plot(x, history.history[metric], label='training')\n",
    "  plt.plot(x, history.history[val_metric], label='validation')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNkDuoj_jWNR"
   },
   "source": [
    "**Model - Bidirectional LSTM with dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Akb1DW4Ye2n7"
   },
   "outputs": [],
   "source": [
    "#model put together as a function to be used as a pipeline element\n",
    "def create_model():\n",
    "  word_embeddings = cust_tokenizer.get_embeddings()\n",
    "  input_dim = cust_tokenizer.get_input_dim()\n",
    "  model = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Embedding(word_embeddings.shape[0], EMBEDDING_DIM, embeddings_initializer=tf.constant_initializer(word_embeddings),\n",
    "                                    input_length =input_dim, trainable=False),\n",
    "          tf.keras.layers.Dropout(0.2),\n",
    "          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),          \n",
    "          tf.keras.layers.Dense(4, activation='softmax')\n",
    "          ])  \n",
    "  \n",
    "  optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "  model.compile(optimizer, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['acc',f1_score], run_eagerly=True)\n",
    "  return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Q9WvH9A4fF4A"
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=50)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"BidirectionalLSTM\", save_best_only=True, verbose=1, mode='max', monitor='f1_score')\n",
    "\n",
    "#wrap the tf model into KerasClassifier to be used with sklearn pipeline\n",
    "wrapper_model =  KerasClassifier(build_fn=create_model, verbose = 4, batch_size=BATCH_SZ, epochs=100, callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-0cFDA8fO_C",
    "outputId": "b4ae955f-77fe-4392-efb5-e99e6cce5182"
   },
   "outputs": [],
   "source": [
    "#construct and invoke the pipeline\n",
    "pipeline = Pipeline([(\"tokenize\", cust_tokenizer),(\"model\", wrapper_model)])\n",
    "pipeline.fit(X, y_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "8-fuoYcNfb8U"
   },
   "outputs": [],
   "source": [
    "#serialize the pipeline elements in a pickle file\n",
    "pickle.dump(pipeline.named_steps['tokenize'], open('tokenizer.pkl','wb'))\n",
    "pickle.dump(pipeline.named_steps['model'].classes_, open('classes.pkl','wb'))\n",
    "pipeline.named_steps['model'].model.save('BidirectionalLSTM.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model_NeuralNetwork_Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
